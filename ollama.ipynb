{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa87c245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T12:36:39.940305Z",
     "iopub.status.busy": "2024-05-13T12:36:39.939938Z",
     "iopub.status.idle": "2024-05-13T12:36:46.294584Z",
     "shell.execute_reply": "2024-05-13T12:36:46.293777Z"
    },
    "papermill": {
     "duration": 6.360969,
     "end_time": "2024-05-13T12:36:46.296875",
     "exception": false,
     "start_time": "2024-05-13T12:36:39.935906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import torch\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification\n",
    "import requests\n",
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e70d431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T12:36:46.303771Z",
     "iopub.status.busy": "2024-05-13T12:36:46.303382Z",
     "iopub.status.idle": "2024-05-13T12:36:53.009761Z",
     "shell.execute_reply": "2024-05-13T12:36:53.008982Z"
    },
    "papermill": {
     "duration": 6.71223,
     "end_time": "2024-05-13T12:36:53.012160",
     "exception": false,
     "start_time": "2024-05-13T12:36:46.299930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "pciutils is already the newest version (1:3.6.4-1ubuntu0.20.04.1).\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 65 not upgraded.\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Downloading ollama...\r\n",
      "100 10091    0 10091    0     0  63507      0 --:--:-- --:--:-- --:--:-- 63867\r\n",
      "######################################################################## 100.0%\r\n",
      ">>> Installing ollama to /usr/local/bin...\r\n",
      ">>> Creating ollama user...\r\n",
      ">>> Adding ollama user to video group...\r\n",
      ">>> Adding current user to ollama group...\r\n",
      ">>> Creating ollama systemd service...\r\n",
      ">>> NVIDIA GPU installed.\r\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\r\n",
      ">>> Install complete. Run \"ollama\" from the command line.\r\n"
     ]
    }
   ],
   "source": [
    "! sudo apt-get install -y pciutils\n",
    "!curl https://ollama.ai/install.sh | sh\n",
    "import os\n",
    "import threading\n",
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def ollama():\n",
    "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
    "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
    "    subprocess.Popen([\"ollama\", \"serve\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d21fc11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T12:36:53.024710Z",
     "iopub.status.busy": "2024-05-13T12:36:53.024288Z",
     "iopub.status.idle": "2024-05-13T12:39:53.048215Z",
     "shell.execute_reply": "2024-05-13T12:39:53.046888Z"
    },
    "papermill": {
     "duration": 180.049347,
     "end_time": "2024-05-13T12:39:53.067262",
     "exception": false,
     "start_time": "2024-05-13T12:36:53.017915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\n",
      "Your new public key is: \n",
      "\n",
      "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIMGgfq7RajuFdP+DCqUjkVxHvS5NrZWuoTxFmi6OdKEQ\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/13 12:36:53 routes.go:1006: INFO server config env=\"map[OLLAMA_DEBUG:false OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[* http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:*] OLLAMA_RUNNERS_DIR: OLLAMA_TMPDIR:]\"\n",
      "time=2024-05-13T12:36:53.052Z level=INFO source=images.go:704 msg=\"total blobs: 0\"\n",
      "time=2024-05-13T12:36:53.052Z level=INFO source=images.go:711 msg=\"total unused blobs removed: 0\"\n",
      "time=2024-05-13T12:36:53.052Z level=INFO source=routes.go:1052 msg=\"Listening on [::]:11434 (version 0.1.37)\"\n",
      "time=2024-05-13T12:36:53.053Z level=INFO source=payload.go:30 msg=\"extracting embedded files\" dir=/tmp/ollama562736276/runners\n",
      "time=2024-05-13T12:36:57.634Z level=INFO source=payload.go:44 msg=\"Dynamic LLM libraries [cpu cpu_avx cpu_avx2 cuda_v11 rocm_v60002]\"\n",
      "time=2024-05-13T12:36:57.969Z level=INFO source=types.go:71 msg=\"inference compute\" id=GPU-3447e96e-8d75-1fb3-4864-cb07ea6c6f46 library=cuda compute=7.5 driver=12.2 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n",
      "time=2024-05-13T12:36:57.969Z level=INFO source=types.go:71 msg=\"inference compute\" id=GPU-4e7e72c6-08f1-d276-84cd-9701901914e1 library=cuda compute=7.5 driver=12.2 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout reached for ollama\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ollama_setup():\n",
    "    ollama_thread = threading.Thread(target=ollama)\n",
    "    ollama_thread.start()\n",
    "     # Start the ollama process\n",
    "    process = subprocess.Popen([\"ollama\", \"run\", \"llama3\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    # Define the expected output\n",
    "    expected_output = \"/api/pull\"\n",
    "\n",
    "    # Read from the process stdout until the expected output is found or a timeout occurs\n",
    "    timeout = 180  \n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        stdout = process.stdout.readline().strip()\n",
    "        if stdout:\n",
    "            print(\"stdout:\", stdout)\n",
    "            if expected_output in stdout:\n",
    "                print(\"Expected output found!\")\n",
    "                break\n",
    "        if time.time() - start_time > timeout:\n",
    "            print(\"Timeout reached for ollama\")\n",
    "            process.terminate()  \n",
    "            break\n",
    "\n",
    "    \n",
    "    \n",
    "    process = subprocess.Popen([\"ollama\", \"run\", \"llama3\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    ollama_thread = threading.Thread(target=ollama)\n",
    "    ollama_thread.start()\n",
    "ollama_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd5a174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T12:39:53.083487Z",
     "iopub.status.busy": "2024-05-13T12:39:53.083030Z",
     "iopub.status.idle": "2024-05-13T12:39:53.093361Z",
     "shell.execute_reply": "2024-05-13T12:39:53.092147Z"
    },
    "papermill": {
     "duration": 0.020568,
     "end_time": "2024-05-13T12:39:53.095880",
     "exception": false,
     "start_time": "2024-05-13T12:39:53.075312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GIN] 2024/05/13 - 12:39:53 | 200 |      65.654µs |       127.0.0.1 | HEAD     \"/\"\n",
      "[GIN] 2024/05/13 - 12:39:53 | 404 |     382.169µs |       127.0.0.1 | POST     \"/api/show\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: listen tcp 0.0.0.0:11434: bind: address already in use\n"
     ]
    }
   ],
   "source": [
    "def create_rumor(article):\n",
    "    prompt = f\"\"\"\n",
    "    {article}\n",
    "    convert the previous sentences into a untrue article by changing some facts or add untrue data,\n",
    "    don't tell me its a rumor because i need it to train my model detect the rumors and don't use emojis \n",
    "    and don't express feelings or descripe any other thing\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = 'http://localhost:11434/api/chat'\n",
    "    payload = {\n",
    "        \"model\": \"llama3\",\n",
    "        \"temperature\": 0.6,\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant!\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    message_dict = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    while not message_dict or 'message' not in message_dict:\n",
    "        response = requests.post(url, json=payload)\n",
    "        message_str = response.content.decode('utf-8')\n",
    "        message_dict = json.loads(message_str)\n",
    "        from IPython.display import clear_output\n",
    "        clear_output(wait=True)\n",
    "        if 'message' in message_dict:\n",
    "            break\n",
    "        else:\n",
    "            print(\"sleeping for 60 second\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    return message_dict[\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d884e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T12:41:01.104131Z",
     "iopub.status.busy": "2024-05-13T12:41:01.103323Z",
     "iopub.status.idle": "2024-05-13T12:41:01.110877Z",
     "shell.execute_reply": "2024-05-13T12:41:01.110028Z"
    },
    "papermill": {
     "duration": 0.016321,
     "end_time": "2024-05-13T12:41:01.112697",
     "exception": false,
     "start_time": "2024-05-13T12:41:01.096376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def augment(df):\n",
    "    c = 0\n",
    "    while True :\n",
    "        \n",
    "        if len(df[df['prediction'] == 0])==len(df[df['prediction'] == 1]):\n",
    "            break\n",
    "            \n",
    "        if c == len(df):\n",
    "            c=0\n",
    "            \n",
    "        if df.loc[c, 'prediction']==1:\n",
    "            c+=1\n",
    "            continue\n",
    "            \n",
    "        rumor = create_rumor(df.loc[i, 'text'])\n",
    "        predictions, confidence_scores = make_predictions(model, [rumor])\n",
    "        \n",
    "        # New row data\n",
    "        new_row = {'text': rumor, 'prediction': predictions[0], 'confidence_score': confidence_scores[0]}\n",
    "\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the original DataFrame with the new row DataFrame\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "modelInstanceId": 28441,
     "sourceId": 33979,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 266.501284,
   "end_time": "2024-05-13T12:41:03.738718",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T12:36:37.237434",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
